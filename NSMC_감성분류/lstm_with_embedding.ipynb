{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9caa14c9",
      "metadata": {
        "id": "9caa14c9"
      },
      "source": [
        "# MidTerm Project: NSMC(Naver Sentiment Movie Corpus) 분류"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62216545",
      "metadata": {
        "id": "62216545"
      },
      "source": [
        "- rating_train.txt는 네이버 영화평을 0 (negative), 1(positive)로 분류해 놓은 자료이고, ratings_test.txt는 같은 영화평의 테스트용 데이터이다.\n",
        "- 이 파일을 가지고 https://github.com/bentrevett/pytorch-sentiment-analysis 에 있는 pytorch sentiment analysis의 방법을 따라  nsmc 분류기를 만들어라\n",
        "- training data에서 evaluation data를 나누어 사용할 수 있다.(필요시)\n",
        "- training data에 나오는 영화평을 가지고 word2vec이나, FastText 등의 임베딩을 만들고 이를 테스트시 사용하라\n",
        "- 제출은 주피터 노트북과 학습된 임베딩 파일 (임베딩 파일이 커서 etl에 탑재가 되지 않으면 압축을 하거나 이메일 등 다른 방법으로 제출)\n",
        "- 화일 이름은 MidTermAssignment_학번_이름\n",
        "- 마감: 2023년 10월 31일 화요일 오후 11시 59분 59초까지!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6be09f6d",
      "metadata": {
        "id": "6be09f6d"
      },
      "source": [
        "## 목표\n",
        "\n",
        "- csv 파일을 읽어서 torchtext를 사용하여 데이터를 신경망에 입력가능한 꼴로 바꾸기\n",
        "- 한국어 데이터 전처리를 위한 함수를 만들고 이를 torchtext에 통합하기 (**새로운 torchtext사용**)\n",
        "- 이미 실습 시간에 관련 모듈 설명됨\n",
        "- 직접 학습한 한국어 단어 임베딩을 torchtext에 통합하여 사용하기\n",
        "- 제시된 여러 모델을 사용하여(transformers 제외) 성능을 향상 시키기\n",
        "- training, evaluation 한 것을 test 데이터에 적용하여 성능을 보이기.\n",
        "- predict를 사용하여 제시된 기사들의 분류 결과를 보이기\n",
        "- 참고 사이트:\n",
        "- [Pytorch Sentiment Analysis](https://github.com/bentrevett/pytorch-sentiment-analysis)에 관련 코드들이 있어 참조할 수 있음"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89fab307",
      "metadata": {
        "id": "89fab307"
      },
      "source": [
        "## 주의사항\n",
        "\n",
        "- 방법\n",
        "1. torchtext 최신 버전 0.14.0으로 작업.\n",
        "- [TorchText 최근버전 documenation](https://pytorch.org/text/0.14.0/index.html)\n",
        "2. 단어 임베딩은 Gensim을 사용하여 자유롭게 구축할 수 있음(차원, 윈도우크기, 학습율 등을 자유롭게 설정)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8bf5999",
      "metadata": {
        "id": "b8bf5999"
      },
      "source": [
        "## 전체 구현 정리\n",
        "- 임베딩 방법 자세히 기술\n",
        "- 데이터 전처리 자세히 기술\n",
        "- rnn, lstm, cnn 등의 방법으로 기술한 것의 성능 차이 기술\n",
        "- 테스트 데이터의 성능 보고\n",
        "- predict한 문장들의 성능 및 분석\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d949aed",
      "metadata": {
        "id": "4d949aed"
      },
      "outputs": [],
      "source": [
        "##프로그래밍 시작\n",
        "## 반드시 각 모듈별로 자세히 주석을 붙이고 설명을 할 것!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 0. 필요한 모듈 다운로드 및  import, 파일 경로(구글 드라이브 마운트)설정 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "knUlmiHfpAkJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knUlmiHfpAkJ",
        "outputId": "30924b33-78e5-4228-eb9c-5104cbf4a4a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.4.1)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.3)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.2)\n",
            "Requirement already satisfied: mecab-python3 in /usr/local/lib/python3.10/dist-packages (1.0.8)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:6 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "g++ is already the newest version (4:11.2.0-1ubuntu1).\n",
            "openjdk-8-jdk is already the newest version (8u382-ga-1~22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 21 not upgraded.\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1-py3 in /usr/local/lib/python3.10/dist-packages (0.5.5.4)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.4.1)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.3)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.2)\n",
            "mecab-ko is already installed\n",
            "mecab-ko-dic is already installed\n",
            "mecab-python is already installed\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "!pip install konlpy\n",
        "!pip install mecab-python3\n",
        "!apt-get update\n",
        "!apt-get install g++ openjdk-8-jdk\n",
        "!pip3 install konlpy JPype1-py3\n",
        "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "YkhntfV5pJes",
      "metadata": {
        "id": "YkhntfV5pJes"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from konlpy.tag import Mecab\n",
        "import torch\n",
        "import torchtext\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.vocab import Vectors\n",
        "from torchtext.vocab import vocab\n",
        "from torchtext import data\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "import numpy as np\n",
        "# from torchtext.legacy import datasets\n",
        "# from torchtext.legacy.data import Iterator, BucketIterator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "NxSARzb8phpk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxSARzb8phpk",
        "outputId": "6340e2e6-2875-471f-84f1-7a9fef72dcca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Vocab 만들기\n",
        "-cnn_with_embedding.ipynb에 자세히 설명이 기술되어 있기에 생략한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "kbXJ0dsYrvAO",
      "metadata": {
        "id": "kbXJ0dsYrvAO"
      },
      "outputs": [],
      "source": [
        "import torchdata.datapipes as dp\n",
        "import torchtext.transforms as T\n",
        "import spacy\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "train_file_path = '/content/drive/MyDrive/nlp/ratings_train.txt'\n",
        "test_file_path = '/content/drive/MyDrive/nlp/ratings_test.txt'\n",
        "\n",
        "data_pipe = dp.iter.IterableWrapper([train_file_path])\n",
        "data_pipe = dp.iter.FileOpener(data_pipe, mode='rb')\n",
        "data_pipe = data_pipe.parse_csv(skip_lines=1, delimiter='\\t', as_tuple=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "SWsvZPCYp-3Q",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWsvZPCYp-3Q",
        "outputId": "f11ceb36-babb-41db-aa50-cf76f8aa5cb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('9976970', '아 더빙.. 진짜 짜증나네요 목소리', '0')\n"
          ]
        }
      ],
      "source": [
        "for sample in data_pipe:\n",
        "    print(sample)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "38Amnnrbr974",
      "metadata": {
        "id": "38Amnnrbr974"
      },
      "outputs": [],
      "source": [
        "def removeAttribution(row):\n",
        "    return row[1:3]\n",
        "data_pipe = data_pipe.map(removeAttribution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "RScLx2hTsEOy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RScLx2hTsEOy",
        "outputId": "a2724b8f-1fc5-4b1c-dbe8-5700d468b009"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('아 더빙.. 진짜 짜증나네요 목소리', '0')\n"
          ]
        }
      ],
      "source": [
        "for sample in data_pipe:\n",
        "    print(sample)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "Ra3iIaSwsLz2",
      "metadata": {
        "id": "Ra3iIaSwsLz2"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "mecab=Mecab()\n",
        "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
        "def tokenizer(text):\n",
        "    text = re.sub(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\", \"\", text)  # 한글과 공백만 남기고 나머지 제거\n",
        "    text = re.sub('^ +', '', text)  # 시작 부분의 여러 개의 연속된 공백 제거\n",
        "    tokens = mecab.morphs(text)\n",
        "    tokens = [word for word in tokens if word not in stopwords]\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "IX9TQfu7-IP-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IX9TQfu7-IP-",
        "outputId": "1573582a-7e6d-4878-a4ba-4b4df781c73c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['아', '더', '빙', '진짜', '짜증', '나', '네요', '목소리']"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer(\"아 더빙.. 진짜 짜증나네요 목소리\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "LBn5BxkAsfqT",
      "metadata": {
        "id": "LBn5BxkAsfqT"
      },
      "outputs": [],
      "source": [
        "def yield_tokens(data_iter):\n",
        "    for text, label in data_iter:\n",
        "        yield tokenizer(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "NH24T6owsNh0",
      "metadata": {
        "id": "NH24T6owsNh0"
      },
      "outputs": [],
      "source": [
        "vocab = build_vocab_from_iterator(yield_tokens(data_pipe), min_freq=2,\n",
        "                                  specials=[\"<unk>\", \"<pad>\"],special_first=True,\n",
        "                                  max_tokens= 25000)\n",
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "HrJDPYhHudQv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrJDPYhHudQv",
        "outputId": "67b373c5-745e-4e59-e144-0770e1f4b979"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', '영화', '다', '고', '하', '을', '보', '게', '지', '있', '없', '좋', '나', '었', '만', '는데', '너무', '봤', '적', '안', '로', '정말', '음', '것', '아', '재밌', '네요', '어', '지만', '같', '진짜', '에서', '기', '했', '네', '점', '않', '거', '았', '수', '되', '면', 'ㅋㅋ', '인', '말', '연기', '최고', '주', '내', '평점', '이런', '던', '어요', '할', '왜', '겠', '해', '스토리', 'ㅋㅋㅋ', '습니다', '듯', '아니', '드라마', '생각', '더', '그', '싶', '사람', '감동', '때', '함', '배우', '본', '까지', '보다', '뭐', '볼', '알', '만들', '내용', '감독', '라', '재미', '그냥', '시간', '재미있', '지루', '중', '잼', '재미없', '였', '년', '쓰레기', '사랑', '못', '냐', '서', '라고', '니']\n"
          ]
        }
      ],
      "source": [
        "print(vocab.get_itos()[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "kT61MPXevIgp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kT61MPXevIgp",
        "outputId": "947b809e-4cae-4c2c-c949-8cea0fbcec1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('아 더빙.. 진짜 짜증나네요 목소리', '0')\n",
            "('흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나', '1')\n",
            "('너무재밓었다그래서보는것을추천한다', '0')\n",
            "('교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정', '0')\n",
            "('사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다', '1')\n",
            "('막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.', '0')\n",
            "('원작의 긴장감을 제대로 살려내지못했다.', '0')\n",
            "('별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단 낫겟다 납치.감금만반복반복..이드라마는 가족도없다 연기못하는사람만모엿네', '0')\n",
            "('액션이 없는데도 재미 있는 몇안되는 영화', '1')\n",
            "('왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?', '1')\n"
          ]
        }
      ],
      "source": [
        "cnt = 0\n",
        "for i in data_pipe:\n",
        "    print(i)\n",
        "    cnt +=1\n",
        "    if cnt == 10:\n",
        "      break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Dataloader 만들기\n",
        "-cnn_with_embedding.ipynb에 자세히 설명이 기술되어 있기에 생략한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "mMYh0ni9sNkb",
      "metadata": {
        "id": "mMYh0ni9sNkb"
      },
      "outputs": [],
      "source": [
        "text_pipeline = lambda x: vocab(tokenizer(x))\n",
        "label_pipeline = lambda x: int(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "BzzPWInMsNm0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzzPWInMsNm0",
        "outputId": "49880ff0-1d94-40e1-81d7-07aa827c723b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "cnn과 다른 부분이 있어 추가 설명한다. cnn에서는 없었던 text_len를 추가해줬다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "wldOLtDasNsI",
      "metadata": {
        "id": "wldOLtDasNsI"
      },
      "outputs": [],
      "source": [
        "#collate_function: process the list of samples to form a batch.\n",
        "# https://androidkt.com/create-dataloader-with-collate_fn-for-variable-length-input-in-pytorch/\n",
        "\n",
        "def lstm_custom_collate_fn(batch):\n",
        "    label_list, text_list,text_len = [], [], []\n",
        "    for (_text,_label) in batch:\n",
        "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "         if(len(processed_text)==0):\n",
        "            continue\n",
        "         label_list.append(label_pipeline(_label))\n",
        "         text_list.append(processed_text)\n",
        "         text_len.append(len(processed_text))\n",
        "\n",
        "    label_list = torch.tensor(label_list, dtype=torch.int64).unsqueeze(dim=1)\n",
        "    text_list = pad_sequence(text_list, padding_value = 1)\n",
        "    return text_list.to(device),label_list.to(device),text_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "VpSVUHIi58hS",
      "metadata": {
        "id": "VpSVUHIi58hS"
      },
      "outputs": [],
      "source": [
        "data_list = list(data_pipe)\n",
        "\n",
        "# 데이터를 train set과 validation set으로 나눔\n",
        "train_data, valid_data = train_test_split(data_list, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "tjJmQidR8x2K",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjJmQidR8x2K",
        "outputId": "ff6e5e00-333b-4545-b0b7-16eb4ec272e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('아 더빙.. 진짜 짜증나네요 목소리', '0'),\n",
              " ('흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나', '1'),\n",
              " ('너무재밓었다그래서보는것을추천한다', '0'),\n",
              " ('교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정', '0'),\n",
              " ('사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다', '1'),\n",
              " ('막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.', '0'),\n",
              " ('원작의 긴장감을 제대로 살려내지못했다.', '0'),\n",
              " ('별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단 낫겟다 납치.감금만반복반복..이드라마는 가족도없다 연기못하는사람만모엿네',\n",
              "  '0'),\n",
              " ('액션이 없는데도 재미 있는 몇안되는 영화', '1'),\n",
              " ('왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?', '1')]"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_list[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "4H11QJtMtrV6",
      "metadata": {
        "id": "4H11QJtMtrV6"
      },
      "outputs": [],
      "source": [
        "lstm_train_dataloader = DataLoader(train_data, batch_size=32,\n",
        "                              shuffle=True, collate_fn=lstm_custom_collate_fn)\n",
        "\n",
        "lstm_valid_dataloader = DataLoader(valid_data, batch_size=32,\n",
        "                              shuffle=True, collate_fn=lstm_custom_collate_fn)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. W2V embedding 모델 만들기\n",
        " cnn_with_embedding.ipynb에 상세한 내용이 있으니까 생략한다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "XbLjn9ESCP7W",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbLjn9ESCP7W",
        "outputId": "da8684b1-38ec-4652-9bc5-231e6755b87d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "150000 50000\n",
            "149995 49997\n",
            "                                                 document  label\n",
            "0                                     아 더빙.. 진짜 짜증나네요 목소리      0\n",
            "1                       흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
            "2                                       너무재밓었다그래서보는것을추천한다      0\n",
            "3                           교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
            "4       사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n",
            "...                                                   ...    ...\n",
            "149995                                인간이 문제지.. 소는 뭔죄인가..      0\n",
            "149996                                      평점이 너무 낮아서...      1\n",
            "149997                    이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?      0\n",
            "149998                        청춘 영화의 최고봉.방황과 우울했던 날들의 자화상      1\n",
            "149999                           한국 영화 최초로 수간하는 내용이 담긴 영화      0\n",
            "\n",
            "[149995 rows x 2 columns]\n",
            "                                                document  label\n",
            "0                                                    굳 ㅋ      1\n",
            "1                                   GDNTOPCLASSINTHECLUB      0\n",
            "2                 뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
            "3                       지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
            "4      3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0\n",
            "...                                                  ...    ...\n",
            "49995          오랜만에 평점 로긴했네ㅋㅋ 킹왕짱 쌈뽕한 영화를 만났습니다 강렬하게 육쾌함      1\n",
            "49996       의지 박약들이나 하는거다 탈영은 일단 주인공 김대희 닮았고 이등병 찐따 OOOO      0\n",
            "49997                 그림도 좋고 완성도도 높았지만... 보는 내내 불안하게 만든다      0\n",
            "49998     절대 봐서는 안 될 영화.. 재미도 없고 기분만 잡치고.. 한 세트장에서 다 해먹네      0\n",
            "49999                                         마무리는 또 왜이래      0\n",
            "\n",
            "[49997 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "train_file_path = '/content/drive/MyDrive/nlp/ratings_train.txt'\n",
        "test_file_path = '/content/drive/MyDrive/nlp/ratings_test.txt'\n",
        "\n",
        "train = pd.read_csv(train_file_path, sep='\\t')\n",
        "test = pd.read_csv(test_file_path, sep='\\t')\n",
        "\n",
        "train = train.drop(columns=['id'])\n",
        "test = test.drop(columns=['id'])\n",
        "print(len(train),len(test))\n",
        "\n",
        "train=train.dropna()\n",
        "test=test.dropna()\n",
        "print(len(train),len(test))\n",
        "print(train)\n",
        "print(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "WpUz8Cw6xL1O",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpUz8Cw6xL1O",
        "outputId": "9fdde7b5-2d83-497f-dbdc-21976622be63"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-58-1e0fb836acdb>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  train['document'] = train['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "149995 119996 29999\n"
          ]
        }
      ],
      "source": [
        "train['document'] = train['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
        "\n",
        "train_data, valid_data = train_test_split(train, test_size=0.2, random_state=42)\n",
        "print(len(train),len(train_data),len(valid_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "-CglUGmZCVm1",
      "metadata": {
        "id": "-CglUGmZCVm1"
      },
      "outputs": [],
      "source": [
        "stopwords = ['의','가','이','은','들','는','과','도','을','를','으로','자','에','와','한','하다']\n",
        "\n",
        "KERNEL_SIZE = [3,4,5] # 총 3개의 kernel size 사용( KERNEL_SIZE, embed_dimension)\n",
        "mecab=Mecab()\n",
        "def tokenizer(text):\n",
        "    token = mecab.morphs(text)\n",
        "    if len(token) < max(KERNEL_SIZE):\n",
        "        for i in range(0, max(KERNEL_SIZE)-len(token)):\n",
        "            token.append('<pad>') # 커널 사이즈 보다 문장의 길이가 작은 경우 에러 방지\n",
        "    return token\n",
        "\n",
        "tokenized_train_data = train_data['document'].apply(lambda sentence: [word for word in tokenizer(sentence) if word not in stopwords])\n",
        "tokenized_validation_data = valid_data['document'].apply(lambda sentence: [word for word in tokenizer(sentence) if word not in stopwords])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "dsoCvAYRCXWV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsoCvAYRCXWV",
        "outputId": "71d42a37-0f09-4cf1-8555-c33157a7390a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "119996 119996\n",
            "29999 29999\n"
          ]
        }
      ],
      "source": [
        "print(len(tokenized_train_data),len(train_data))\n",
        "print(len(tokenized_validation_data),len(valid_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "KWMmiHaNCYXr",
      "metadata": {
        "id": "KWMmiHaNCYXr"
      },
      "outputs": [],
      "source": [
        "w2v_model = Word2Vec(tokenized_train_data, min_count = 2, vector_size = 100, workers = 3, window = 5, sg = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "HJEWH79VCZeb",
      "metadata": {
        "id": "HJEWH79VCZeb"
      },
      "outputs": [],
      "source": [
        "w2v_model.save(\"w2v.model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. LSTM with word2vec\n",
        "더 상세한 내용은 cnn_with_embedding.ipynb에 있다.여기서는 cnn_with_embedding과 다른 점만 설명한다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "uyour9BsCYcZ",
      "metadata": {
        "id": "uyour9BsCYcZ"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "미리 학습된 워드 임베딩(w2v_model)을 활용한 lstm 모델을 정의했다.\n",
        "trained된 embedding을 넣는 부분만 달라졌다.\n",
        "구체적인 모델은 수업시간에 배운대로 정의했다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "SV-h-_A1wfpm",
      "metadata": {
        "id": "SV-h-_A1wfpm"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import gensim\n",
        "import torch.nn.functional as F\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers,\n",
        "                 bidirectional, dropout,pad_idx):\n",
        "\n",
        "        super().__init__()\n",
        "        #여기서 아까 만든 w2v 모델을 넣는다.\n",
        "        w2vmodel = gensim.models.KeyedVectors.load('w2v.model')\n",
        "        weights = w2vmodel.wv\n",
        "        # With pretrained embeddings\n",
        "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(weights.vectors), padding_idx=pad_idx)\n",
        "\n",
        "\n",
        "        self.rnn = nn.LSTM(embedding_dim,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional,\n",
        "                           dropout=dropout)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    #text_len이 추가되었음에 유의하자\n",
        "    def forward(self, text, text_len):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "\n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "\n",
        "        #pack sequence\n",
        "        # lengths need to be on CPU!\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, lengths = text_len, enforce_sorted = False)\n",
        "\n",
        "\n",
        "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "\n",
        "        #unpack sequence\n",
        "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "\n",
        "        #output = [sent len, batch size, hid dim * num directions]\n",
        "        #output over padding tokens are zero tensors\n",
        "\n",
        "        #hidden = [num layers * num directions, batch size, hid dim]\n",
        "        #cell = [num layers * num directions, batch size, hid dim]\n",
        "\n",
        "        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
        "        #and apply dropout\n",
        "\n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "\n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "\n",
        "        return self.fc(hidden)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "3BH8KejE_iHJ",
      "metadata": {
        "id": "3BH8KejE_iHJ"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = len(vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX =  w2v_model.wv.key_to_index['<pad>']\n",
        "\n",
        "model = RNN(INPUT_DIM,\n",
        "            EMBEDDING_DIM,\n",
        "            HIDDEN_DIM,\n",
        "            OUTPUT_DIM,\n",
        "            N_LAYERS,\n",
        "            BIDIRECTIONAL,\n",
        "            DROPOUT,PAD_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vHkyYDqvwfw0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHkyYDqvwfw0",
        "outputId": "a4fd049d-eaff-49c4-df41-7029a9d17a5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model has 2,310,657 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. 생성한 lstm을 Training\n",
        "\n",
        " cnn_with_embedding.ipynb에 상세한 내용이 있으니까 자세한 내용은 생략한다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "aOBp53sFwfzM",
      "metadata": {
        "id": "aOBp53sFwfzM"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u8Gyws_xxcwy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8Gyws_xxcwy",
        "outputId": "4ee50c76-e73d-460b-d7c2-aa20e70553b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "U-rwkibiwf1c",
      "metadata": {
        "id": "U-rwkibiwf1c"
      },
      "outputs": [],
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division\n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "text_len이 추가되어 있ㅇ므을 유의해서 함수를 작성한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ViH0k3t6wf3s",
      "metadata": {
        "id": "ViH0k3t6wf3s"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "\n",
        "def train(dataloader):\n",
        "    model.train()\n",
        "    epoch_loss, epoch_acc = 0, 0\n",
        "    log_interval = len(dataloader)\n",
        "    start_time = time.time()\n",
        "\n",
        "    #text_len이 추가되었음에 유의해야 한다.\n",
        "    for idx, (text, label, text_len) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        predicted_label = model(text, text_len)\n",
        "        loss = criterion(predicted_label, label.float())\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "        optimizer.step()\n",
        "        epoch_acc += binary_accuracy(predicted_label,label).item()\n",
        "        epoch_loss += loss.item()\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
        "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
        "                                            epoch_loss/len(dataloader)))\n",
        "            #total_acc, total_count = 0, 0\n",
        "            start_time = time.time()\n",
        "\n",
        "    return epoch_loss / len(dataloader), epoch_acc / len(dataloader)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "kK5vEOS1wf6E",
      "metadata": {
        "id": "kK5vEOS1wf6E"
      },
      "outputs": [],
      "source": [
        "def evaluate(dataloader):\n",
        "    model.eval()\n",
        "    epoch_loss, epoch_acc = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for idx, (text, label, text_len) in enumerate(dataloader):\n",
        "            predicted_label = model(text, text_len)\n",
        "            loss = criterion(predicted_label, label.float())\n",
        "            epoch_acc += binary_accuracy(predicted_label,label).item()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(dataloader), epoch_acc / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "AYKiYcX1upD6",
      "metadata": {
        "id": "AYKiYcX1upD6"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ivethECiwf8P",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivethECiwf8P",
        "outputId": "7cbfaf80-4e38-4a8c-bc3c-b245c56cc56c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 1m 12s\n",
            "\tTrain Loss: 0.536 | Train Acc: 71.62%\n",
            "\t Val. Loss: 0.446 |  Val. Acc: 78.56%\n",
            "Epoch: 02 | Epoch Time: 1m 11s\n",
            "\tTrain Loss: 0.461 | Train Acc: 77.01%\n",
            "\t Val. Loss: 0.416 |  Val. Acc: 80.39%\n",
            "Epoch: 03 | Epoch Time: 1m 11s\n",
            "\tTrain Loss: 0.436 | Train Acc: 78.76%\n",
            "\t Val. Loss: 0.395 |  Val. Acc: 81.37%\n",
            "Epoch: 04 | Epoch Time: 1m 8s\n",
            "\tTrain Loss: 0.419 | Train Acc: 79.83%\n",
            "\t Val. Loss: 0.390 |  Val. Acc: 81.86%\n",
            "Epoch: 05 | Epoch Time: 1m 9s\n",
            "\tTrain Loss: 0.409 | Train Acc: 80.58%\n",
            "\t Val. Loss: 0.380 |  Val. Acc: 82.20%\n",
            "Epoch: 06 | Epoch Time: 1m 9s\n",
            "\tTrain Loss: 0.399 | Train Acc: 81.05%\n",
            "\t Val. Loss: 0.382 |  Val. Acc: 82.63%\n",
            "Epoch: 07 | Epoch Time: 1m 9s\n",
            "\tTrain Loss: 0.395 | Train Acc: 81.30%\n",
            "\t Val. Loss: 0.374 |  Val. Acc: 82.79%\n",
            "Epoch: 08 | Epoch Time: 1m 10s\n",
            "\tTrain Loss: 0.389 | Train Acc: 81.59%\n",
            "\t Val. Loss: 0.378 |  Val. Acc: 83.02%\n",
            "Epoch: 09 | Epoch Time: 1m 9s\n",
            "\tTrain Loss: 0.384 | Train Acc: 81.91%\n",
            "\t Val. Loss: 0.369 |  Val. Acc: 83.12%\n",
            "Epoch: 10 | Epoch Time: 1m 8s\n",
            "\tTrain Loss: 0.382 | Train Acc: 82.05%\n",
            "\t Val. Loss: 0.373 |  Val. Acc: 83.21%\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "for epoch in range(EPOCHS):\n",
        "    epoch_start_time = time.time()\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss, train_acc = train(lstm_train_dataloader)\n",
        "    valid_loss, valid_acc = evaluate(lstm_valid_dataloader)\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'lstm_with_w2v.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6. 테스트 데이터 evalute \n",
        " cnn_with_embedding.ipynb에 상세한 내용이 있으니까 생략한다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6H74oKsZwpNf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6H74oKsZwpNf",
        "outputId": "3478efc9-0a3d-41b1-ccee-f0f54ef02437"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.380 | Test Acc: 82.96%\n"
          ]
        }
      ],
      "source": [
        "test_file_path = '/content/drive/MyDrive/nlp/ratings_test.txt'\n",
        "\n",
        "test_data_pipe = dp.iter.IterableWrapper([test_file_path])\n",
        "test_data_pipe = dp.iter.FileOpener(test_data_pipe, mode='rb')\n",
        "test_data_pipe = test_data_pipe.parse_csv(skip_lines=1, delimiter='\\t', as_tuple=True)\n",
        "test_data_pipe = test_data_pipe.map(removeAttribution)\n",
        "\n",
        "test_dataloader = DataLoader(list(test_data_pipe), batch_size=16,\n",
        "                              shuffle=True, collate_fn=lstm_custom_collate_fn)\n",
        "model.eval()\n",
        "test_loss, test_acc = evaluate(test_dataloader)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75deb3c7",
      "metadata": {
        "id": "75deb3c7"
      },
      "source": [
        "#7. Inference\n",
        " cnn_with_embedding.ipynb에 상세한 내용이 있으니까 생략한다.\n",
        "\n",
        "- 다음 문장들을 모델에 넣었을 때 그 결과를 도출하는 inference 작성\n",
        "- 0(부정)/1(긍정)\n",
        "- 아래 문장의 정답은 1/1/0/0/1/1/1/0/0/0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "yK17kBnsUzw9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK17kBnsUzw9",
        "outputId": "c7345f8c-4826-4471-ad35-f97583e81200"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#model.load_state_dict(torch.load('/content/lstm_with_w2v.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "7qoS5AVMUkwr",
      "metadata": {
        "id": "7qoS5AVMUkwr"
      },
      "outputs": [],
      "source": [
        "def predict_nsmc(model, sentence, min_len=5):\n",
        "  threshold=0.8\n",
        "  hey=[(sentence,'0')]\n",
        "  hey_dataloader = DataLoader(hey, batch_size=1,\n",
        "                                shuffle=True, collate_fn=lstm_custom_collate_fn)\n",
        "  model.eval()\n",
        "  for idx, (text, label, text_len) in enumerate(hey_dataloader):\n",
        "        prediction = torch.sigmoid(model(text, text_len))\n",
        "        print(prediction.item(),\" : \", sentence)\n",
        "        prediction = 1 if prediction.item() >= threshold else 0\n",
        "\n",
        "  return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "915f058a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "915f058a",
        "outputId": "fd01a372-e3ff-41ec-9632-d273e6f10298"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9975007176399231  :  잔잔한 감동... 오래 기억에 남아요... 우리 시대의 평범한 가족 모습이 솔직하게 담겨 있네요. 그리고 한 소녀의 성장기도 아름답게 표현했습니다.\n",
            "0.9771487712860107  :  한 사람의 삶을 한 화면에서 완전히 이해할 수 없다는 것을 더욱 명확하게 깨닫게 해주는 작품입니다. 밴 애플렉과 션 윌의 연기는 볼만하고, 복 받은 캐릭터들이 감동을 전해줍니다.\n",
            "0.28178760409355164  :  티비 드라마보다 못한 영화. 그 당시에는 티비 드라마가 한국 영화보다 더 흥미로웠다.\n",
            "0.9200431108474731  :  이 작품은 클래식을 위한 드라마나 청춘 성장 드라마와는 다른 주제를 다루고 있는데, 그 주제가 명확하지 않아 혼란스럽습니다. 현실을 고발하려는 의도는 알겠지만, 이 작품은 다소 심각한 드라마 중 하나입니다. 부채도사는 어디로..ㅠㅠ\n",
            "0.9938376545906067  :  이 작품을 통해 그들의 쾌락적인 삶을 엿볼 수 있고, 우리는 다른 형태의 쾌락을 느낍니다. 그들이 추잡하게 보일 수 있지만, 결국 우리도 돈을 추구하며 부유한 삶을 상상하는 것이 현실입니다. 이 영화는 감독의 메시지를 느끼게 합니다.\n",
            "0.9955370426177979  :  미식축구를 다시 생각하게 만든 감동적인 영화입니다. 개인적으로 감명 깊었습니다.\n",
            "0.994544506072998  :  의외로 흥미로운 영화로, 지루하지 않은 사극 멜로였습니다. 캐릭터들이 매력적으로 표현되었어요.\n",
            "0.5149775743484497  :  캐릭터들 중에서 할아버지를 제외하고는 짜증을 유발하는 매력적인 캐릭터가 없다는 점이 아쉽습니다.\n",
            "0.7111943364143372  :  엔딩 임팩트가 부족합니다. 더 흥미로웠다면 좋았을 것 같아요.\n",
            "0.011933899484574795  :  주연배우들이 지루하고, 압축된 스토리가 조금 부족한 것 같습니다. 으윽.\n",
            "[1, 1, 0, 1, 1, 1, 1, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "result=[]\n",
        "sentence=\"잔잔한 감동... 오래 기억에 남아요... 우리 시대의 평범한 가족 모습이 솔직하게 담겨 있네요. 그리고 한 소녀의 성장기도 아름답게 표현했습니다.\"\n",
        "result.append(predict_nsmc(model, sentence))\n",
        "sentence=\"한 사람의 삶을 한 화면에서 완전히 이해할 수 없다는 것을 더욱 명확하게 깨닫게 해주는 작품입니다. 밴 애플렉과 션 윌의 연기는 볼만하고, 복 받은 캐릭터들이 감동을 전해줍니다.\"\n",
        "result.append(predict_nsmc(model, sentence))\n",
        "sentence=\"티비 드라마보다 못한 영화. 그 당시에는 티비 드라마가 한국 영화보다 더 흥미로웠다.\"\n",
        "result.append(predict_nsmc(model, sentence))\n",
        "sentence=\"이 작품은 클래식을 위한 드라마나 청춘 성장 드라마와는 다른 주제를 다루고 있는데, 그 주제가 명확하지 않아 혼란스럽습니다. 현실을 고발하려는 의도는 알겠지만, 이 작품은 다소 심각한 드라마 중 하나입니다. 부채도사는 어디로..ㅠㅠ\"\n",
        "result.append(predict_nsmc(model, sentence))\n",
        "sentence=\"이 작품을 통해 그들의 쾌락적인 삶을 엿볼 수 있고, 우리는 다른 형태의 쾌락을 느낍니다. 그들이 추잡하게 보일 수 있지만, 결국 우리도 돈을 추구하며 부유한 삶을 상상하는 것이 현실입니다. 이 영화는 감독의 메시지를 느끼게 합니다.\"\n",
        "result.append(predict_nsmc(model, sentence))\n",
        "sentence=\"미식축구를 다시 생각하게 만든 감동적인 영화입니다. 개인적으로 감명 깊었습니다.\"\n",
        "result.append(predict_nsmc(model, sentence))\n",
        "sentence=\"의외로 흥미로운 영화로, 지루하지 않은 사극 멜로였습니다. 캐릭터들이 매력적으로 표현되었어요.\"\n",
        "result.append(predict_nsmc(model, sentence))\n",
        "sentence=\"캐릭터들 중에서 할아버지를 제외하고는 짜증을 유발하는 매력적인 캐릭터가 없다는 점이 아쉽습니다.\"\n",
        "result.append(predict_nsmc(model, sentence))\n",
        "sentence=\"엔딩 임팩트가 부족합니다. 더 흥미로웠다면 좋았을 것 같아요.\"\n",
        "result.append(predict_nsmc(model, sentence))\n",
        "sentence=\"주연배우들이 지루하고, 압축된 스토리가 조금 부족한 것 같습니다. 으윽.\"\n",
        "result.append(predict_nsmc(model, sentence))\n",
        "\n",
        "print(result)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
